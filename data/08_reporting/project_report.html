<!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>Amazon books coldstart - project report</title>
        <style>
/* From extension vscode.github */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

.vscode-dark img[src$=\#gh-light-mode-only],
.vscode-light img[src$=\#gh-dark-mode-only] {
	display: none;
}

</style>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css">
<link href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css" rel="stylesheet" type="text/css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
<style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', system-ui, 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
        <style>
.task-list-item {
    list-style-type: none;
}

.task-list-item-checkbox {
    margin-left: -20px;
    vertical-align: middle;
    pointer-events: none;
}
</style>
        
    </head>
    <body class="vscode-body vscode-light">
        <h1 id="amazon-books-coldstart---project-report">Amazon books coldstart - project report</h1>
<h2 id="table-of-contents">Table of contents</h2>
<ul>
<li><a href="#amazon-books-coldstart---project-report">Amazon books coldstart - project report</a>
<ul>
<li><a href="#table-of-contents">Table of contents</a></li>
<li><a href="#problem-description">Problem description</a>
<ul>
<li><a href="#dataset">Dataset</a></li>
<li><a href="#problem-statement">Problem statement</a></li>
<li><a href="#metrics">Metrics</a>
<ul>
<li><a href="#ways-to-compute-metrics">Ways to compute metrics</a></li>
<li><a href="#dataset-1">Dataset</a></li>
<li><a href="#how-many-users-to-query">How many users to query</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#methods-idea">Methods (idea)</a>
<ul>
<li><a href="#first-model-idea">First model idea</a></li>
<li><a href="#second-model-idea">Second model idea</a></li>
<li><a href="#book-embeddings-model">Book embeddings model</a></li>
</ul>
</li>
<li><a href="#description-of-the-implementation-details">Description of the implementation (details)</a>
<ul>
<li><a href="#first-model-idea-1">First model idea</a>
<ul>
<li><a href="#simple_approach">Simple_approach</a></li>
<li><a href="#book_embedding_approach">Book_embedding_approach</a></li>
</ul>
</li>
<li><a href="#second-model-idea-1">Second model idea</a>
<ul>
<li><a href="#user_embeddings">User_embeddings</a></li>
<li><a href="#user_embeddings2">User_embeddings2</a></li>
<li><a href="#user_embeddings3">User_embeddings3</a></li>
</ul>
</li>
<li><a href="#faiss">FAISS</a></li>
<li><a href="#model-embeddings-and-training">Model embeddings and training</a></li>
</ul>
</li>
<li><a href="#results">Results</a>
<ul>
<li><a href="#detailed-results">Detailed results</a></li>
<li><a href="#summary">Summary</a></li>
<li><a href="#conclusions">Conclusions</a></li>
<li><a href="#perspectives">Perspectives</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="problem-description">Problem description</h2>
<h3 id="dataset">Dataset</h3>
<p>We use <a href="https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews?resource=download">Amazon Books Reviews</a> dataset from Kaggle.
<img src="file:////home/rzepa/Studia/Semestr-10/ADM/amazon-books-coldstart/data/08_reporting/imgs/dataset.png" alt="Data"></p>
<p>Here are short reports generated by <code>pandas-profiling</code> library:</p>
<ul>
<li><a href="./Books_report.html">Books</a></li>
<li><a href="./Ratings_report.html">Reviews</a></li>
</ul>
<p>Links to report notebooks, dataset description</p>
<h3 id="problem-statement">Problem statement</h3>
<p>We decided to tackle the 'cold start' problem. Read more on <a href="https://en.wikipedia.org/wiki/Cold_start_(recommender_systems)#New_item">Wikipedia</a>. Given a new book, we want to recommend it to users that will actually read it. It's not a trivial problem because we can use only book's metadata.</p>
<h3 id="metrics">Metrics</h3>
<p>Problem task: given book predict users that will read it.</p>
<p>We use a few metrics build from a few blocks described below. First has 2 possibilities, second 3 possibilities and third 2 possibilities what gives 12 values in total. We report the average value over the selected dataset for those metrics.</p>
<h4 id="ways-to-compute-metrics">Ways to compute metrics</h4>
<p>Assume book has <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> reviews. Our system predicted <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mo>+</mo><mi>i</mi></mrow><annotation encoding="application/x-tex">c + i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">c</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> useres in total (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">c</span></span></span></span> correctly and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> incorrectly).</p>
<p>Precision: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>c</mi><mrow><mi>c</mi><mo>+</mo><mi>i</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{c}{c + i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0987em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6954em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>Recall: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>c</mi><mi>r</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{c}{r}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0404em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6954em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>Those are standard metrics for such problems. They seem to be reasonable in this problem.</p>
<h4 id="dataset-1">Dataset</h4>
<p>We query program on whole dataset, books that have at least 20 reviews and books that have at most 19 reviews. Small number of reviews may have more noise and the problem should be harder on this part of the dataset. Bigger number of reviews should make the problem easier.</p>
<h4 id="how-many-users-to-query">How many users to query</h4>
<p>We query for <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>20</mn></mrow><annotation encoding="application/x-tex">20</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">20</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> users. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>20</mn></mrow><annotation encoding="application/x-tex">20</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">20</span></span></span></span> users seems to be a good benchmark for a new book. We simply get a new book and recommend it to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>20</mn></mrow><annotation encoding="application/x-tex">20</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">20</span></span></span></span> users. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> users sounds like a good way to evaluate the actual precision of the algorithm, since we see how many of the selected users match the real users that read the book.</p>
<h2 id="methods-idea">Methods (idea)</h2>
<h4 id="first-model-idea">First model idea</h4>
<p>For a query:</p>
<ul>
<li>find books closets to ours (using similarity measure between books)</li>
<li>for those books rate users that rated books that are similar to the one from the query</li>
</ul>
<p>Our baseline algorithm used information about book's authors, categories and publisher to define similarity of books. It is Simple_approach(True, f1, f1). To define similarity measure we used information about book's authors, categories, publisher, description embedding and book embedding.</p>
<h4 id="second-model-idea">Second model idea</h4>
<p>Embed users into a space based on embeddings of book they reviewed. Then, for a query search for users closest to the book embedding. To embed we used description embedding and book embedding.</p>
<h3 id="book-embeddings-model">Book embeddings model</h3>
<p>This approach tries to utilize deep learning. The main idea is to create an embedding for each new book - based on description, author, publisher and category. Then, find neighboring books in the embedding space and recommend new book to the users that read those books.</p>
<h2 id="description-of-the-implementation-details">Description of the implementation (details)</h2>
<h3 id="first-model-idea-1">First model idea</h3>
<h4 id="simple_approach">Simple_approach</h4>
<p>Books similarity is counted as follows:
(10 x number_of_same_authors + 1 x (same_publisher) + 5 x (same_category)) * (add_fixed_part == True) + distance_mapping(distance) x (is_in_clostest_books).
We used the following distance mapping functions:</p>
<ul>
<li>f1: 0 (not adding distance part at all)</li>
<li>f2: 20 * (2 - x) (distance should be between 0 and 2 and we needed to reverse the order)</li>
<li>f3: 20 / x (we needed to reverse the order)</li>
<li>f4: 20 (fixed reward for being in the set of the closest books)</li>
</ul>
<p>User score based on selected books is counted as follows:
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>u</mi><msub><mi>m</mi><mrow><mo stretchy="false">(</mo><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo separator="true">,</mo><mi>b</mi><mi>o</mi><mi>o</mi><mi>k</mi><mi>I</mi><mi>d</mi><mo stretchy="false">)</mo><mo>∈</mo><mi>r</mi><mi>e</mi><mi>v</mi><mi>i</mi><mi>e</mi><mi>w</mi><mi>s</mi></mrow></msub><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mi>M</mi><mi>a</mi><mi>p</mi><mi>p</mi><mi>i</mi><mi>n</mi><mi>g</mi><mo stretchy="false">(</mo><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>b</mi><mi>o</mi><mi>o</mi><mi>k</mi><mi>S</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo stretchy="false">[</mo><mi>b</mi><mi>o</mi><mi>o</mi><mi>k</mi><mi>I</mi><mi>d</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">sum_{(score, bookId) \in reviews} scoreMapping(score) * bookScore[bookId]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3552em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">u</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">score</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight">oo</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">I</span><span class="mord mathnormal mtight">d</span><span class="mclose mtight">)</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight">re</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span><span class="mord mathnormal">score</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">a</span><span class="mord mathnormal">pp</span><span class="mord mathnormal">in</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal">score</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">b</span><span class="mord mathnormal">oo</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">core</span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mord mathnormal">oo</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal">d</span><span class="mclose">]</span></span></span></span>
We used the following scoreMapping functions:</p>
<ul>
<li>f1: identity (values in range [1, 5])</li>
<li>f2: score - 3.5 (values in range [-2.5, 2.5] - this implements intuition that user won't want to read the book similar to book they didn't like)</li>
<li>f3: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mi>x</mi><mo>−</mo><mn>3.5</mn></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{1 + e ^ {x - 3.5}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2484em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mbin mtight">−</span><span class="mord mtight">3.5</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> (sigmoid to smooth the score instead of a linear function)</li>
</ul>
<p>For a given query we query for 20 * number_of_users_to_return books and then we find best number_of_users_to_return users based on those books.</p>
<h4 id="book_embedding_approach">Book_embedding_approach</h4>
<p>This solution differs from Simple_approach in computing books similarity. It uses books embedding to compute the similarity and then maps it using funcitons f1-f4 described above and identity function. The similarity can be computed using cosine similarity and L2 norm (this can be specified when creating the model).</p>
<p>The second part of this algorithm is the same as in Simple_approach.</p>
<h3 id="second-model-idea-1">Second model idea</h3>
<h4 id="user_embeddings">User_embeddings</h4>
<p>Embedding of a user is a weighted average of embeddings of book description they rated with the ratings being the weights.</p>
<p>For the query we simply return users closest to the embedding of description of the queried book.</p>
<h4 id="user_embeddings2">User_embeddings2</h4>
<p>This model took max_clusters as a parameter. For each user we took description embeddings of all books they rated (with ratings as weights) and clustered them into max_clusters clusters using kmeans algorithm. Then, we embedded the user in a max_cluster places in the space (the centers of the clusters).</p>
<p>For the query we simply return distinct users closest to the embedding of description of the queried book.</p>
<h4 id="user_embeddings3">User_embeddings3</h4>
<p>This model is similar to the User_embeddings2, but it uses book embeddings instead of description embeddings and has extra parameter which indicates if we want to compute L2 or cosine similarity.</p>
<h3 id="faiss">FAISS</h3>
<p>Embeddings calculation requires also a way to find nearest neighbors (Euclidean distance or cosine similarity). We used FAISS library for this purpose. It is a library for efficient similarity search and clustering of dense vectors. It is developed by Facebook AI Research. <a href="https://github.com/facebookresearch/faiss">GitHub repository</a>.</p>
<h3 id="model-embeddings-and-training">Model embeddings and training</h3>
<p>Creating book embedding consisted of a few steps:</p>
<ul>
<li>We used <a href="https://www.sbert.net/index.html">SentenceTransformer</a> library to embed book description. It provides the user with set of pretrained models that can be used to embed sentences. We used <code>all-MiniLM-L6-v2</code> model due to its speed and accuracy.</li>
<li>The other embedding needed was author, category and publisher. We opted for torch trainable embeddings. We used <code>nn.Embedding</code> for publisher and <code>nn.EmbeddingBag</code> for author and category. Then we concatenated all embeddings and passed them through a few linear layers to get the final embedding.</li>
<li>The last step was to design loss function. For this purpose we used <a href="https://kevinmusgrave.github.io/pytorch-metric-learning/">pytorch-metric-learing</a>. We wanted two books to be close (cosine similarity) if they were read by the same user.</li>
</ul>
<h2 id="results">Results</h2>
<h3 id="detailed-results">Detailed results</h3>
<p>Values are presented in percents (tested on validation set)</p>
<table>
<thead>
<tr>
<th></th>
<th>20 users to predict</th>
<th>20 users to predict</th>
<th>20 users to predict</th>
<th>20 users to predict</th>
<th>20 users to predict</th>
<th>20 users to predict</th>
<th>number_of_reviews users to predict</th>
<th>number_of_reviews users to predict</th>
<th>number_of_reviews users to predict</th>
<th>number_of_reviews users to predict</th>
<th style="text-align:center">number_of_reviews users to predict</th>
<th style="text-align:center">number_of_reviews users to predict</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>all books</td>
<td>all books</td>
<td>below 20 reviews</td>
<td>below 20 reviews</td>
<td>above 19 reviews</td>
<td>above 19 reviews</td>
<td>all books</td>
<td>all books</td>
<td>below 20 reviews</td>
<td>below 20 reviews</td>
<td style="text-align:center">above 19 reviews</td>
<td style="text-align:center">above 19 reviews</td>
</tr>
<tr>
<td>model name</td>
<td>precision</td>
<td>recall</td>
<td>precision</td>
<td>recall</td>
<td>precision</td>
<td>recall</td>
<td>precision</td>
<td>recall</td>
<td>precision</td>
<td>recall</td>
<td style="text-align:center">precision</td>
<td style="text-align:center">recall</td>
</tr>
<tr>
<td>Simple_approach True f1 f1 (baseline)</td>
<td>3</td>
<td>6</td>
<td>1</td>
<td>7</td>
<td>13</td>
<td>5</td>
<td>5</td>
<td>5</td>
<td>5</td>
<td>5</td>
<td style="text-align:center">8</td>
<td style="text-align:center">8</td>
</tr>
<tr>
<td>Simple_approach True f2 f1</td>
<td>3</td>
<td>7</td>
<td>1</td>
<td>7</td>
<td>13</td>
<td>5</td>
<td>5</td>
<td>5</td>
<td>5</td>
<td>5</td>
<td style="text-align:center">8</td>
<td style="text-align:center">8</td>
</tr>
<tr>
<td>Simple_approach True f3 f1</td>
<td>5</td>
<td>12</td>
<td>3</td>
<td>12</td>
<td>23</td>
<td>10</td>
<td>10</td>
<td>10</td>
<td>9</td>
<td>9</td>
<td style="text-align:center">22</td>
<td style="text-align:center">21</td>
</tr>
<tr>
<td>Simple_approach True f4 f1</td>
<td>2</td>
<td>5</td>
<td>1</td>
<td>6</td>
<td>10</td>
<td>4</td>
<td>4</td>
<td>3</td>
<td>3</td>
<td>3</td>
<td style="text-align:center">6</td>
<td style="text-align:center">5</td>
</tr>
<tr>
<td>Simple_approach True f1 f2</td>
<td>3</td>
<td>6</td>
<td>1</td>
<td>6</td>
<td>13</td>
<td>5</td>
<td>5</td>
<td>5</td>
<td>4</td>
<td>4</td>
<td style="text-align:center">8</td>
<td style="text-align:center">7</td>
</tr>
<tr>
<td>Simple_approach True f2 f2</td>
<td>2</td>
<td>6</td>
<td>1</td>
<td>6</td>
<td>12</td>
<td>5</td>
<td>4</td>
<td>4</td>
<td>4</td>
<td>4</td>
<td style="text-align:center">7</td>
<td style="text-align:center">7</td>
</tr>
<tr>
<td>Simple_approach True f3 f2</td>
<td>4</td>
<td>10</td>
<td>2</td>
<td>10</td>
<td>22</td>
<td>10</td>
<td>8</td>
<td>8</td>
<td>7</td>
<td>7</td>
<td style="text-align:center">18</td>
<td style="text-align:center">17</td>
</tr>
<tr>
<td>Simple_approach True f4 f2</td>
<td>2</td>
<td>5</td>
<td>1</td>
<td>5</td>
<td>9</td>
<td>3</td>
<td>3</td>
<td>3</td>
<td>3</td>
<td>3</td>
<td style="text-align:center">5</td>
<td style="text-align:center">5</td>
</tr>
<tr>
<td>Simple_approach True f1 f3</td>
<td>2</td>
<td>5</td>
<td>1</td>
<td>5</td>
<td>12</td>
<td>4</td>
<td>4</td>
<td>4</td>
<td>3</td>
<td>3</td>
<td style="text-align:center">7</td>
<td style="text-align:center">6</td>
</tr>
<tr>
<td>Simple_approach True f2 f3</td>
<td>2</td>
<td>5</td>
<td>1</td>
<td>5</td>
<td>11</td>
<td>4</td>
<td>3</td>
<td>3</td>
<td>2</td>
<td>2</td>
<td style="text-align:center">6</td>
<td style="text-align:center">6</td>
</tr>
<tr>
<td>Simple_approach True f3 f3</td>
<td>5</td>
<td>10</td>
<td>2</td>
<td>10</td>
<td>22</td>
<td>10</td>
<td>9</td>
<td>9</td>
<td>8</td>
<td>8</td>
<td style="text-align:center">21</td>
<td style="text-align:center">20</td>
</tr>
<tr>
<td>Simple_approach True f4 f3</td>
<td>2</td>
<td>4</td>
<td>1</td>
<td>4</td>
<td>8</td>
<td>3</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td style="text-align:center">4</td>
<td style="text-align:center">4</td>
</tr>
<tr>
<td>Simple_approach False f2 f1</td>
<td>2</td>
<td>6</td>
<td>1</td>
<td>6</td>
<td>11</td>
<td>4</td>
<td>4</td>
<td>4</td>
<td>3</td>
<td>3</td>
<td style="text-align:center">6</td>
<td style="text-align:center">6</td>
</tr>
<tr>
<td>Simple_approach False f1 f1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td>Simple_approach False f3 f1</td>
<td>5</td>
<td>11</td>
<td>2</td>
<td>12</td>
<td>23</td>
<td>10</td>
<td>10</td>
<td>10</td>
<td>9</td>
<td>8</td>
<td style="text-align:center">21</td>
<td style="text-align:center">21</td>
</tr>
<tr>
<td>Simple_approach False f4 f1</td>
<td>2</td>
<td>5</td>
<td>1</td>
<td>5</td>
<td>8</td>
<td>3</td>
<td>3</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td style="text-align:center">4</td>
<td style="text-align:center">4</td>
</tr>
<tr>
<td>Simple_approach False f1 f2</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td>Simple_approach False f2 f2</td>
<td>2</td>
<td>5</td>
<td>1</td>
<td>5</td>
<td>10</td>
<td>4</td>
<td>3</td>
<td>3</td>
<td>3</td>
<td>3</td>
<td style="text-align:center">6</td>
<td style="text-align:center">6</td>
</tr>
<tr>
<td>Simple_approach False f3 f2</td>
<td>4</td>
<td>10</td>
<td>2</td>
<td>10</td>
<td>22</td>
<td>9</td>
<td>8</td>
<td>8</td>
<td>7</td>
<td>7</td>
<td style="text-align:center">17</td>
<td style="text-align:center">17</td>
</tr>
<tr>
<td>Simple_approach False f4 f2</td>
<td>1</td>
<td>4</td>
<td>1</td>
<td>4</td>
<td>7</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td style="text-align:center">4</td>
<td style="text-align:center">4</td>
</tr>
<tr>
<td>Simple_approach False f1 f3</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td>Simple_approach False f2 f3</td>
<td>2</td>
<td>4</td>
<td>1</td>
<td>4</td>
<td>9</td>
<td>3</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td style="text-align:center">5</td>
<td style="text-align:center">5</td>
</tr>
<tr>
<td>Simple_approach False f3 f3</td>
<td>5</td>
<td>10</td>
<td>2</td>
<td>10</td>
<td>22</td>
<td>10</td>
<td>9</td>
<td>9</td>
<td>8</td>
<td>8</td>
<td style="text-align:center">20</td>
<td style="text-align:center">20</td>
</tr>
<tr>
<td>Simple_approach False f4 f3</td>
<td>1</td>
<td>3</td>
<td>1</td>
<td>4</td>
<td>6</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td style="text-align:center">3</td>
<td style="text-align:center">3</td>
</tr>
<tr>
<td>User_embeddings</td>
<td>4</td>
<td>8</td>
<td>2</td>
<td>8</td>
<td>20</td>
<td>7</td>
<td>7</td>
<td>6</td>
<td>6</td>
<td>16</td>
<td style="text-align:center">16</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td>User_embeddings2 1</td>
<td>4</td>
<td>8</td>
<td>2</td>
<td>8</td>
<td>20</td>
<td>9</td>
<td>7</td>
<td>7</td>
<td>6</td>
<td>6</td>
<td style="text-align:center">16</td>
<td style="text-align:center">16</td>
</tr>
<tr>
<td>User_embeddings2 4</td>
<td>5</td>
<td>10</td>
<td>2</td>
<td>10</td>
<td>23</td>
<td>10</td>
<td>9</td>
<td>8</td>
<td>7</td>
<td>7</td>
<td style="text-align:center">20</td>
<td style="text-align:center">19</td>
</tr>
<tr>
<td>User_embeddings3 4 True</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td>User_embeddings3 4 False</td>
<td>4</td>
<td>8</td>
<td>2</td>
<td>8</td>
<td>20</td>
<td>8</td>
<td>7</td>
<td>7</td>
<td>6</td>
<td>6</td>
<td style="text-align:center">17</td>
<td style="text-align:center">16</td>
</tr>
<tr>
<td>Book_embedding_approach f5 f1 True</td>
<td>2</td>
<td>4</td>
<td>1</td>
<td>4</td>
<td>9</td>
<td>3</td>
<td>3</td>
<td>3</td>
<td>2</td>
<td>2</td>
<td style="text-align:center">5</td>
<td style="text-align:center">5</td>
</tr>
<tr>
<td>Book_embedding_approach f2 f1 False</td>
<td>4</td>
<td>8</td>
<td>2</td>
<td>8</td>
<td>19</td>
<td>8</td>
<td>8</td>
<td>8</td>
<td>7</td>
<td>7</td>
<td style="text-align:center">15</td>
<td style="text-align:center">15</td>
</tr>
<tr>
<td>Book_embedding_approach f2 f2 False</td>
<td>2</td>
<td>3</td>
<td>1</td>
<td>3</td>
<td>11</td>
<td>4</td>
<td>4</td>
<td>4</td>
<td>4</td>
<td>3</td>
<td style="text-align:center">5</td>
<td style="text-align:center">5</td>
</tr>
<tr>
<td>Book_embedding_approach f2 f3 False</td>
<td>4</td>
<td>7</td>
<td>2</td>
<td>8</td>
<td>17</td>
<td>7</td>
<td>7</td>
<td>7</td>
<td>6</td>
<td>6</td>
<td style="text-align:center">14</td>
<td style="text-align:center">14</td>
</tr>
<tr>
<td>Book_embedding_approach f3 f1 False</td>
<td>5</td>
<td>11</td>
<td>2</td>
<td>11</td>
<td>23</td>
<td>10</td>
<td>10</td>
<td>10</td>
<td>8</td>
<td>8</td>
<td style="text-align:center">21</td>
<td style="text-align:center">21</td>
</tr>
<tr>
<td>Book_embedding_approach f3 f2 False</td>
<td>4</td>
<td>9</td>
<td>2</td>
<td>9</td>
<td>22</td>
<td>10</td>
<td>8</td>
<td>8</td>
<td>7</td>
<td>7</td>
<td style="text-align:center">18</td>
<td style="text-align:center">17</td>
</tr>
<tr>
<td>Book_embedding_approach f3 f3 False</td>
<td>5</td>
<td>10</td>
<td>2</td>
<td>10</td>
<td>22</td>
<td>10</td>
<td>9</td>
<td>9</td>
<td>8</td>
<td>8</td>
<td style="text-align:center">21</td>
<td style="text-align:center">20</td>
</tr>
<tr>
<td>Book_embedding_approach f5 f1 False</td>
<td>1</td>
<td>3</td>
<td>1</td>
<td>3</td>
<td>6</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td style="text-align:center">4</td>
<td style="text-align:center">3</td>
</tr>
<tr>
<td>Book_embedding_approach f5 f2 False</td>
<td>1</td>
<td>3</td>
<td>1</td>
<td>3</td>
<td>5</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td style="text-align:center">3</td>
<td style="text-align:center">3</td>
</tr>
<tr>
<td>Book_embedding_approach f5 f3 False</td>
<td>1</td>
<td>2</td>
<td>0</td>
<td>2</td>
<td>5</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td style="text-align:center">3</td>
<td style="text-align:center">3</td>
</tr>
</tbody>
</table>
<p>Models with the best results (smaller table to easier comparison)</p>
<table>
<thead>
<tr>
<th></th>
<th>20 users to predict</th>
<th>20 users to predict</th>
<th>20 users to predict</th>
<th>20 users to predict</th>
<th>20 users to predict</th>
<th>20 users to predict</th>
<th>number_of_reviews users to predict</th>
<th>number_of_reviews users to predict</th>
<th>number_of_reviews users to predict</th>
<th>number_of_reviews users to predict</th>
<th style="text-align:center">number_of_reviews users to predict</th>
<th style="text-align:center">number_of_reviews users to predict</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>all books</td>
<td>all books</td>
<td>below 20 reviews</td>
<td>below 20 reviews</td>
<td>above 19 reviews</td>
<td>above 19 reviews</td>
<td>all books</td>
<td>all books</td>
<td>below 20 reviews</td>
<td>below 20 reviews</td>
<td style="text-align:center">above 19 reviews</td>
<td style="text-align:center">above 19 reviews</td>
</tr>
<tr>
<td>model name</td>
<td>precision</td>
<td>recall</td>
<td>precision</td>
<td>recall</td>
<td>precision</td>
<td>recall</td>
<td>precision</td>
<td>recall</td>
<td>precision</td>
<td>recall</td>
<td style="text-align:center">precision</td>
<td style="text-align:center">recall</td>
</tr>
<tr>
<td>Simple_approach True f3 f1</td>
<td>5</td>
<td>12</td>
<td>3</td>
<td>12</td>
<td>23</td>
<td>10</td>
<td>10</td>
<td>10</td>
<td>9</td>
<td>9</td>
<td style="text-align:center">22</td>
<td style="text-align:center">21</td>
</tr>
<tr>
<td>Simple_approach True f3 f2</td>
<td>4</td>
<td>10</td>
<td>2</td>
<td>10</td>
<td>22</td>
<td>10</td>
<td>8</td>
<td>8</td>
<td>7</td>
<td>7</td>
<td style="text-align:center">18</td>
<td style="text-align:center">17</td>
</tr>
<tr>
<td>Simple_approach True f3 f3</td>
<td>5</td>
<td>10</td>
<td>2</td>
<td>10</td>
<td>22</td>
<td>10</td>
<td>9</td>
<td>9</td>
<td>8</td>
<td>8</td>
<td style="text-align:center">21</td>
<td style="text-align:center">20</td>
</tr>
<tr>
<td>Simple_approach False f3 f1</td>
<td>5</td>
<td>11</td>
<td>2</td>
<td>12</td>
<td>23</td>
<td>10</td>
<td>10</td>
<td>10</td>
<td>9</td>
<td>8</td>
<td style="text-align:center">21</td>
<td style="text-align:center">21</td>
</tr>
<tr>
<td>Simple_approach False f3 f2</td>
<td>4</td>
<td>10</td>
<td>2</td>
<td>10</td>
<td>22</td>
<td>9</td>
<td>8</td>
<td>8</td>
<td>7</td>
<td>7</td>
<td style="text-align:center">17</td>
<td style="text-align:center">17</td>
</tr>
<tr>
<td>Simple_approach False f3 f3</td>
<td>5</td>
<td>10</td>
<td>2</td>
<td>10</td>
<td>22</td>
<td>10</td>
<td>9</td>
<td>9</td>
<td>8</td>
<td>8</td>
<td style="text-align:center">20</td>
<td style="text-align:center">20</td>
</tr>
<tr>
<td>User_embeddings</td>
<td>4</td>
<td>8</td>
<td>2</td>
<td>8</td>
<td>20</td>
<td>7</td>
<td>7</td>
<td>6</td>
<td>6</td>
<td>16</td>
<td style="text-align:center">16</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td>User_embeddings2 1</td>
<td>4</td>
<td>8</td>
<td>2</td>
<td>8</td>
<td>20</td>
<td>9</td>
<td>7</td>
<td>7</td>
<td>6</td>
<td>6</td>
<td style="text-align:center">16</td>
<td style="text-align:center">16</td>
</tr>
<tr>
<td>User_embeddings2 4</td>
<td>5</td>
<td>10</td>
<td>2</td>
<td>10</td>
<td>23</td>
<td>10</td>
<td>9</td>
<td>8</td>
<td>7</td>
<td>7</td>
<td style="text-align:center">20</td>
<td style="text-align:center">19</td>
</tr>
<tr>
<td>User_embeddings3 4 False</td>
<td>4</td>
<td>8</td>
<td>2</td>
<td>8</td>
<td>20</td>
<td>8</td>
<td>7</td>
<td>7</td>
<td>6</td>
<td>6</td>
<td style="text-align:center">17</td>
<td style="text-align:center">16</td>
</tr>
<tr>
<td>Book_embedding_approach f3 f1 False</td>
<td>5</td>
<td>11</td>
<td>2</td>
<td>11</td>
<td>23</td>
<td>10</td>
<td>10</td>
<td>10</td>
<td>8</td>
<td>8</td>
<td style="text-align:center">21</td>
<td style="text-align:center">21</td>
</tr>
<tr>
<td>Book_embedding_approach f3 f2 False</td>
<td>4</td>
<td>9</td>
<td>2</td>
<td>9</td>
<td>22</td>
<td>10</td>
<td>8</td>
<td>8</td>
<td>7</td>
<td>7</td>
<td style="text-align:center">18</td>
<td style="text-align:center">17</td>
</tr>
<tr>
<td>Book_embedding_approach f3 f3 False</td>
<td>5</td>
<td>10</td>
<td>2</td>
<td>10</td>
<td>22</td>
<td>10</td>
<td>9</td>
<td>9</td>
<td>8</td>
<td>8</td>
<td style="text-align:center">21</td>
<td style="text-align:center">20</td>
</tr>
</tbody>
</table>
<p>Best models from each model type</p>
<table>
<thead>
<tr>
<th></th>
<th>20 users to predict</th>
<th>20 users to predict</th>
<th>20 users to predict</th>
<th>20 users to predict</th>
<th>20 users to predict</th>
<th>20 users to predict</th>
<th>number_of_reviews users to predict</th>
<th>number_of_reviews users to predict</th>
<th>number_of_reviews users to predict</th>
<th>number_of_reviews users to predict</th>
<th style="text-align:center">number_of_reviews users to predict</th>
<th style="text-align:center">number_of_reviews users to predict</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>all books</td>
<td>all books</td>
<td>below 20 reviews</td>
<td>below 20 reviews</td>
<td>above 19 reviews</td>
<td>above 19 reviews</td>
<td>all books</td>
<td>all books</td>
<td>below 20 reviews</td>
<td>below 20 reviews</td>
<td style="text-align:center">above 19 reviews</td>
<td style="text-align:center">above 19 reviews</td>
</tr>
<tr>
<td>model name</td>
<td>precision</td>
<td>recall</td>
<td>precision</td>
<td>recall</td>
<td>precision</td>
<td>recall</td>
<td>precision</td>
<td>recall</td>
<td>precision</td>
<td>recall</td>
<td style="text-align:center">precision</td>
<td style="text-align:center">recall</td>
</tr>
<tr>
<td>Simple_approach True f3 f1</td>
<td>5</td>
<td>12</td>
<td>3</td>
<td>12</td>
<td>23</td>
<td>10</td>
<td>10</td>
<td>10</td>
<td>9</td>
<td>9</td>
<td style="text-align:center">22</td>
<td style="text-align:center">21</td>
</tr>
<tr>
<td>User_embeddings</td>
<td>4</td>
<td>8</td>
<td>2</td>
<td>8</td>
<td>20</td>
<td>7</td>
<td>7</td>
<td>6</td>
<td>6</td>
<td>6</td>
<td style="text-align:center">16</td>
<td style="text-align:center">16</td>
</tr>
<tr>
<td>User_embeddings2 4</td>
<td>5</td>
<td>10</td>
<td>2</td>
<td>10</td>
<td>23</td>
<td>10</td>
<td>9</td>
<td>8</td>
<td>7</td>
<td>7</td>
<td style="text-align:center">20</td>
<td style="text-align:center">19</td>
</tr>
<tr>
<td>User_embeddings3 4 False</td>
<td>4</td>
<td>8</td>
<td>2</td>
<td>8</td>
<td>20</td>
<td>8</td>
<td>7</td>
<td>7</td>
<td>6</td>
<td>6</td>
<td style="text-align:center">17</td>
<td style="text-align:center">16</td>
</tr>
<tr>
<td>Book_embedding_approach f3 f1 False</td>
<td>5</td>
<td>11</td>
<td>2</td>
<td>11</td>
<td>23</td>
<td>10</td>
<td>10</td>
<td>10</td>
<td>8</td>
<td>8</td>
<td style="text-align:center">21</td>
<td style="text-align:center">21</td>
</tr>
</tbody>
</table>
<p>We see that many approaches led to a very similar results. This suggest that creating significantly better solution is harder and requires a new trick or technique. Our models reached 23% percents precision on books with at least 20 reviews which sounds like a very good result.</p>
<p>Results on test set.</p>
<table>
<thead>
<tr>
<th></th>
<th>20 users to predict</th>
<th>20 users to predict</th>
<th>20 users to predict</th>
<th>20 users to predict</th>
<th>20 users to predict</th>
<th>20 users to predict</th>
<th>number_of_reviews users to predict</th>
<th>number_of_reviews users to predict</th>
<th>number_of_reviews users to predict</th>
<th>number_of_reviews users to predict</th>
<th style="text-align:center">number_of_reviews users to predict</th>
<th style="text-align:center">number_of_reviews users to predict</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>all books</td>
<td>all books</td>
<td>below 20 reviews</td>
<td>below 20 reviews</td>
<td>above 19 reviews</td>
<td>above 19 reviews</td>
<td>all books</td>
<td>all books</td>
<td>below 20 reviews</td>
<td>below 20 reviews</td>
<td style="text-align:center">above 19 reviews</td>
<td style="text-align:center">above 19 reviews</td>
</tr>
<tr>
<td>model name</td>
<td>precision</td>
<td>recall</td>
<td>precision</td>
<td>recall</td>
<td>precision</td>
<td>recall</td>
<td>precision</td>
<td>recall</td>
<td>precision</td>
<td>recall</td>
<td style="text-align:center">precision</td>
<td style="text-align:center">recall</td>
</tr>
<tr>
<td>Simple approach True f3 f1</td>
<td>5</td>
<td>12</td>
<td>3</td>
<td>12</td>
<td>24</td>
<td>10</td>
<td>10</td>
<td>10</td>
<td>9</td>
<td>9</td>
<td style="text-align:center">22</td>
<td style="text-align:center">22</td>
</tr>
<tr>
<td>User embeddings</td>
<td>4</td>
<td>8</td>
<td>2</td>
<td>8</td>
<td>20</td>
<td>8</td>
<td>7</td>
<td>7</td>
<td>6</td>
<td>6</td>
<td style="text-align:center">16</td>
<td style="text-align:center">16</td>
</tr>
<tr>
<td>User_embedding2 4</td>
<td>5</td>
<td>10</td>
<td>2</td>
<td>10</td>
<td>23</td>
<td>9</td>
<td>9</td>
<td>8</td>
<td>7</td>
<td>7</td>
<td style="text-align:center">20</td>
<td style="text-align:center">19</td>
</tr>
<tr>
<td>User_embedding3 4 False</td>
<td>4</td>
<td>8</td>
<td>2</td>
<td>8</td>
<td>20</td>
<td>8</td>
<td>7</td>
<td>7</td>
<td>6</td>
<td>6</td>
<td style="text-align:center">17</td>
<td style="text-align:center">16</td>
</tr>
<tr>
<td>Book_embedding_approach f3 f1 False</td>
<td>5</td>
<td>11</td>
<td>2</td>
<td>11</td>
<td>24</td>
<td>10</td>
<td>10</td>
<td>10</td>
<td>9</td>
<td>9</td>
<td style="text-align:center">22</td>
<td style="text-align:center">21</td>
</tr>
</tbody>
</table>
<p>We see that there is almost no difference between results on validation and test set. Both of them were generated in a similar manner and are big. Thus, this is not a surprise.</p>
<h3 id="summary">Summary</h3>
<ul>
<li>We analysed the dataset and split it into train, validation and test.</li>
<li>We deviced ideas and models for solution to our problem.</li>
<li>We trained description embeddings and book embeddings.</li>
<li>We created a few models with different ideas and hyperparametes.</li>
<li>We analysed performance of our models and embedding to make them better.</li>
<li>We tested models and presented results.</li>
</ul>
<p>Training models was very hard, since the dataset was big and the models were learning slowly.</p>
<h3 id="conclusions">Conclusions</h3>
<p>Embeddings seem to not be trained well enough, since they work better on L2 metric instead of cosine similarity. This is weird and unexpected, since they were trained on consine similarity loss. Most of the best performing models had pretty similar results. This suggests that there is some obstacle none of them was able to pass. The models final performance was pretty nice. For a given book with at least 20 reviews it suggested almost 5 users that would read it. This means that in real life if we are given a book that has potential we would likely promote it.</p>
<p>Embeddings of description performed well and adding rest of book data to the embedding training process did not improve them. This is quite intuitive, since description of the book is long in comparison to other book data like author or publisher.</p>
<p>Training models on huge dataset is not an easy thing. The computations are slow, models are learning very slowly, analysis of the dataset is hard, since it is not possible to &quot;go through&quot; the dataset. Also, recommening books sounds like a hard task for a few reasons:</p>
<ul>
<li>the fact if people like the book or not depends also on factors other than the book itself (our humor etc.)</li>
<li>some people may be forced to read different books (for school, studies etc.) and it is not possible for our models to detect such cases</li>
<li>from our perspective it would be hard to recommend a good book for us</li>
<li>people can make reviews of books randomly</li>
<li>the final score people give is just a number and does not contains much information in comparison to the whole opinion they had about the book</li>
</ul>
<h3 id="perspectives">Perspectives</h3>
<p>Due to bad speed performance of model training we were not able to train it properly. We believe that we haven't explored this idea enough and it would be worth to try to train it properly. Another idea would be to create and end-to-end model which would take a book description and return probability over users. Performance of model using only books' descriptions is promising.</p>

        <script async src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script>
        
    </body>
    </html>